{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>hair_color</th>\n",
       "      <th>eyeglasses</th>\n",
       "      <th>smiling</th>\n",
       "      <th>young</th>\n",
       "      <th>human</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2308</th>\n",
       "      <td>2531</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>4830</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>907</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>522</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_name  hair_color  eyeglasses  smiling  young  human\n",
       "2308       2531           2           1        1      1     -1\n",
       "82           92           1           1        1      1     -1\n",
       "4401       4830          -1          -1       -1      1      1\n",
       "817         907           0          -1       -1      1      1\n",
       "471         522           1          -1        1      1      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%store -r \n",
    "#restore train, validate, and test dataframes from other notebook\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '/home/ilyas/dev/AMLSassignment/images/2531.png' -> '/home/ilyas/dev/AMLSassignment/images/train/young/1/2531.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2db661356ce7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m symlink_classes_images(train, validate, test, \n\u001b[1;32m     73\u001b[0m                        \u001b[0mimagesPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidatePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestPath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                        rowName, reset_images=False, delete_dirs=False)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-2db661356ce7>\u001b[0m in \u001b[0;36msymlink_classes_images\u001b[0;34m(train, validate, test, imagesPath, trainPath, validatePath, testPath, rowName, reset_images, delete_dirs)\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0mnewFilePath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidateFilePath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewFilePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestFilePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestFilePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewFilePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/home/ilyas/dev/AMLSassignment/images/2531.png' -> '/home/ilyas/dev/AMLSassignment/images/train/young/1/2531.png'"
     ]
    }
   ],
   "source": [
    "def reset_images_to_main_dir(delete_dirs=True):\n",
    "    dest_dir = './images/'\n",
    "    walker = os.walk(dest_dir)\n",
    "    rem_dirs = walker.__next__()[1]\n",
    " \n",
    "    for data in walker:\n",
    "        for files in data[2]:\n",
    "            try:\n",
    "                shutil.move(data[0] + os.sep + files, dest_dir)\n",
    "            except shutil.Error:\n",
    "                print(shutil.Error)\n",
    "                continue\n",
    "    if delete_dirs:\n",
    "        for dirs in rem_dirs:\n",
    "            shutil.rmtree(dest_dir + os.sep + dirs)\n",
    "\n",
    "def symlink_classes_images(train, validate, test, \n",
    "                           imagesPath,\n",
    "                           trainPath,\n",
    "                           validatePath,\n",
    "                           testPath,\n",
    "                           rowName,\n",
    "                           reset_images=False, \n",
    "                           delete_dirs=False):\n",
    "    if reset_images:\n",
    "        reset_images_to_main_dir(delete_dirs=delete_dirs)\n",
    "    newPaths = [trainPath, validatePath, testPath]\n",
    "    dfList = [train, validate, test]\n",
    "    for path in newPaths:\n",
    "        if os.path.isdir(path)==False:\n",
    "            os.mkdir(path)\n",
    "    \n",
    "    for df in dfList:\n",
    "        for idx, row in df.iterrows():\n",
    "            className = int(row[rowName])\n",
    "            pathAppend = str(className)+'/'\n",
    "            \n",
    "            fileName = str(int(row['file_name']))+'.png'\n",
    "            filePath = os.path.join(imagesPath, fileName)\n",
    "            trainClassPath = os.path.join(trainPath, pathAppend)\n",
    "            trainFilePath = os.path.join(trainClassPath, fileName)\n",
    "            validateClassPath = os.path.join(validatePath, pathAppend)\n",
    "            validateFilePath = os.path.join(validateClassPath, fileName)\n",
    "            testClassPath = os.path.join(testPath, pathAppend)\n",
    "            testFilePath = os.path.join(testClassPath, fileName)\n",
    "            classPaths = [trainClassPath, validateClassPath, testClassPath]\n",
    "            for path in classPaths:\n",
    "                if os.path.isdir(path)==False:\n",
    "                    os.mkdir(path)\n",
    "            if(df.equals(test)):\n",
    "                newFilePath = testFilePath\n",
    "            if(df.equals(train)):\n",
    "                newFilePath = trainFilePath\n",
    "            if(df.equals(validate)):\n",
    "                newFilePath = validateFilePath\n",
    "            if os.path.isfile(filePath):\n",
    "                os.symlink(filePath, newFilePath)\n",
    "            elif os.path.isfile(testFilePath):\n",
    "                os.symlink(testFilePath, newFilePath)\n",
    "            elif os.path.isfile(validateFilePath):\n",
    "                os.symlink(validateFilePath, newFilePath)\n",
    "            elif os.path.isfile(trainFilePath):\n",
    "                os.symlink(trainFilePath, newFilePath)\n",
    "            else:\n",
    "                print(\"File missing: \", fileName)\n",
    "\n",
    "imagesPath = os.path.abspath('./images/')\n",
    "trainPath = os.path.abspath('./images/train/young/')\n",
    "validatePath = os.path.abspath('./images/validate/young/')\n",
    "testPath = os.path.abspath('./images/test/young/')\n",
    "rowName = 'young'\n",
    "symlink_classes_images(train, validate, test, \n",
    "                       imagesPath, trainPath, validatePath, testPath,\n",
    "                       rowName, reset_images=False, delete_dirs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_young = train[['file_name', 'young']]\n",
    "train_young = train_young.replace(to_replace=-1, value=0).reset_index(drop=True)\n",
    "validate_young = validate[['file_name', 'young']]\n",
    "validate_young = validate_young.replace(to_replace=-1, value=0).reset_index(drop=True)\n",
    "test_young = test[['file_name', 'young']]\n",
    "test_young = test_young.replace(to_replace=-1, value=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    2176\n",
      "0     563\n",
      "Name: young, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "n_young = train_young['young'].value_counts()\n",
    "print(n_young)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(3, 128, 128)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "#model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2739 images belonging to 2 classes.\n",
      "Found 913 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "def get_ImageDataGenerator(shear_range=0, \n",
    "                           zoom_range=0, \n",
    "                           horizontal_flip=False):\n",
    "    datagen = ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "                shear_range=0,\n",
    "                zoom_range=0,\n",
    "                horizontal_flip=False,\n",
    "                data_format='channels_first')\n",
    "    \n",
    "    return datagen\n",
    "\n",
    "def get_flow_from_directory(ImageDataGenerator,\n",
    "                            img_dir,\n",
    "                            target_size=(128,128),\n",
    "                            class_mode='binary',\n",
    "                            batch_size=32,\n",
    "                            shuffle=True,\n",
    "                            seed=123):\n",
    "    gen = ImageDataGenerator.flow_from_directory(\n",
    "                            directory=img_dir,\n",
    "                            target_size=target_size,\n",
    "                            class_mode=class_mode,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=shuffle,\n",
    "                            seed=seed,\n",
    "                            follow_links=True)\n",
    "    return gen\n",
    "\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = get_ImageDataGenerator(shear_range=0,\n",
    "                                       zoom_range=0,\n",
    "                                       horizontal_flip=False)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = get_ImageDataGenerator()\n",
    "#Takes the dataframe and the path to a directory and \n",
    "#generates batches of augmented/normalized data.\n",
    "\n",
    "trainPath = './images/train/young/'\n",
    "validatePath = './images/validate/young/'\n",
    "batch_size = 32\n",
    "target_size=(128,128)\n",
    "class_mode='binary'\n",
    "shuffle=True\n",
    "seed=123\n",
    "\n",
    "train_gen = get_flow_from_directory(train_datagen,\n",
    "                                    trainPath,\n",
    "                                    target_size,\n",
    "                                    class_mode,\n",
    "                                    batch_size,\n",
    "                                    shuffle,\n",
    "                                    seed)\n",
    "\n",
    "validation_gen = get_flow_from_directory(test_datagen,\n",
    "                                    validatePath,\n",
    "                                    target_size,\n",
    "                                    class_mode,\n",
    "                                    batch_size,\n",
    "                                    shuffle,\n",
    "                                    seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "#class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 #['cartoon', 'human'],\n",
    "                                                 #train_human.head(2720)['human'])\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0.001,\n",
    "                              patience=0,\n",
    "                              verbose=1, \n",
    "                              mode='auto',\n",
    "                              restore_best_weights=True)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', \n",
    "                       factor=0.2, \n",
    "                       patience=0, \n",
    "                       verbose=1, \n",
    "                       mode='auto', \n",
    "                       min_delta=0.01, \n",
    "                       cooldown=0, \n",
    "                       min_lr=0.001)\n",
    "train_gen.reset()\n",
    "validation_gen.reset()\n",
    "\n",
    "train_steps=train_gen.n/train_gen.batch_size\n",
    "valid_steps=validation_gen.n/validation_gen.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.59375 28.53125\n",
      "2739.0 913.0\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 128, 128)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 126, 126)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 63, 63)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 63, 63)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 63, 63)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 64, 61, 61)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 64, 30, 30)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64, 30, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 64, 30, 30)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 64, 28, 28)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 64, 14, 14)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64, 14, 14)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               6423040   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 6,535,297\n",
      "Trainable params: 6,535,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(train_steps, valid_steps)\n",
    "print(train_steps*train_gen.batch_size, valid_steps*validation_gen.batch_size)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "86/85 [==============================] - 18127s 211s/step - loss: 0.4771 - acc: 0.8142 - val_loss: 0.3598 - val_acc: 0.8697\n",
      "Epoch 2/50\n",
      "19/85 [=====>........................] - ETA: 5:13 - loss: 0.3416 - acc: 0.8635"
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator=train_gen,\n",
    "                    steps_per_epoch=train_steps,\n",
    "                    validation_data=validation_gen,\n",
    "                    validation_steps=valid_steps,\n",
    "                    epochs=50,\n",
    "                    callbacks=[earlyStopping, LR],\n",
    "                    class_weight = 'auto')\n",
    "\n",
    "#model.save_weights('.h5')\n",
    "model.save_weights('young_detection_from_dir.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_gen = get_flow_from_directory(test_datagen,\n",
    "                                        validatePath,\n",
    "                                        target_size,\n",
    "                                        class_mode,\n",
    "                                        1,\n",
    "                                        False)\n",
    "\n",
    "validation_gen.reset()\n",
    "\n",
    "model.evaluate_generator(generator=validation_gen, steps=913, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPath = './images/test/young/'\n",
    "\n",
    "\n",
    "test_gen = get_flow_from_directory(test_datagen,\n",
    "                                    testPath,\n",
    "                                    target_size,\n",
    "                                    class_mode,\n",
    "                                    1,\n",
    "                                    False)\n",
    "\n",
    "test_gen.reset()\n",
    "\n",
    "model.evaluate_generator(generator=test_gen, steps=913, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen.reset()\n",
    "probabilities = model.predict_generator(test_gen,verbose=1,steps=len(test_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "output_df = pd.DataFrame(\n",
    "    {'filename': test_gen.filenames,\n",
    "     'y_true': test_gen.classes,\n",
    "     'y_pred': list(map(int, np.rint(probabilities).flatten()))\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df_wrong = output_df.query('y_true != y_pred')\n",
    "output_df_wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = test_gen.classes\n",
    "y_pred = np.rint(probabilities)\n",
    "confusion_matrix(y_true=y_true, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AMLSassignment",
   "language": "python",
   "name": "amlsassignment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
