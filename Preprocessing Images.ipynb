{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>hair_color</th>\n",
       "      <th>eyeglasses</th>\n",
       "      <th>smiling</th>\n",
       "      <th>young</th>\n",
       "      <th>human</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_name  hair_color  eyeglasses  smiling  young  human\n",
       "0          1           1          -1        1      1     -1\n",
       "1          2           4          -1        1      1      1\n",
       "2          3           5          -1        1     -1     -1\n",
       "3          7           2          -1        1      1     -1\n",
       "4          8           3          -1        1      1     -1"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filteredDf = pd.read_csv('attribute_list_filtered.csv')\n",
    "filteredDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x0_-1' 'x0_0' 'x0_1' 'x0_2' 'x0_3' 'x0_4' 'x0_5' 'x1_-1' 'x1_1' 'x2_-1'\n",
      " 'x2_1' 'x3_-1' 'x3_1' 'x4_-1' 'x4_1']\n",
      "(4565, 15)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#one-hot-enconding:\n",
    "def get_one_hot():\n",
    "    df = pd.read_csv('attribute_list_filtered.csv')\n",
    "    fileNameDf = df['file_name']\n",
    "    df = df.drop('file_name', 1)\n",
    "    enc = OneHotEncoder(categories='auto')\n",
    "    enc.fit(df)\n",
    "    onehotlabels = enc.transform(df).toarray()\n",
    "    print(enc.get_feature_names())\n",
    "    print(onehotlabels.shape)\n",
    "    oneHotCols = [\"hair_-1\", \"hair_0\", \"hair_1\", \"hair_2\", \"hair_3\", \"hair_4\",\n",
    "              \"hair_5\", \"eyeglasses_-1\", \"eyeglasses_1\", \"smiling_-1\", \"smiling_1\", \n",
    "              \"young_-1\", \"young_1\", \"human_-1\", \"human_1\"]\n",
    "    oneHotDf = pd.DataFrame(onehotlabels, columns = oneHotCols)\n",
    "    oneHotDf = pd.concat([fileNameDf, oneHotDf], axis=1)\n",
    "    oneHotDf.to_csv('attribute_list_filtered_onehot.csv', index=False)\n",
    "    return oneHotDf\n",
    "\n",
    "oneHotDf = get_one_hot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4565"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(oneHotDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './images/2.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d76db5aff087>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         fill_mode='nearest')\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./images/2.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mimg_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#shape: (3, 256, 256)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mimg_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mimg_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#adds extra dimension, shape: (1,3,256,256)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/environments/AMLSassignment/lib/python3.6/site-packages/keras_preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    496\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    497\u001b[0m                           'The use of `array_to_img` requires PIL.')\n\u001b[0;32m--> 498\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/environments/AMLSassignment/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2608\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2609\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2610\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './images/2.png'"
     ]
    }
   ],
   "source": [
    "#data augmentation to prevent over-fitting example:\n",
    "'''https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html'''\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "img = load_img('./images/2.png')\n",
    "img_arr = img_to_array(img) #shape: (3, 256, 256)\n",
    "img_arr = img_arr.reshape((1,)+img_arr.shape) #adds extra dimension, shape: (1,3,256,256)\n",
    "\n",
    "#generate batches of randomly transformed images, save in transformed dir\n",
    "if os.path.isdir('transformed')==False:\n",
    "    os.mkdir('transformed')\n",
    "\n",
    "i = 0\n",
    "flow = datagen.flow(img_arr, batch_size=1,\n",
    "                    save_to_dir='transformed', \n",
    "                    save_prefix='2', save_format='png')\n",
    "for batch in flow:\n",
    "    i+=1\n",
    "    if i>20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train length:  2739 | ratio:  0.6\n",
      "validate length:  913 | ratio:  0.2\n",
      "test length:  913 | ratio:  0.2\n"
     ]
    }
   ],
   "source": [
    "#splitting into train, validation, and test sets:\n",
    "import numpy as np\n",
    "def split_dataset_random(df, validation_split=0.2, test_split=0.2, seed=0):\n",
    "    np.random.seed(seed) #if the same seed is used the same random split will be produced\n",
    "    train_split = 1 - validation_split - test_split\n",
    "    indeces_array = [int(train_split*len(df)), int((1-test_split)*len(df))]\n",
    "    '''example, [2, 3] would, for axis=0, result in\n",
    "\n",
    "        ary[:2]\n",
    "        ary[2:3]\n",
    "        ary[3:]\n",
    "\n",
    "    '''\n",
    "    train, validate, test = np.split(df.sample(frac=1), indeces_array)\n",
    "    return train, validate, test\n",
    "\n",
    "train, validate, test = split_dataset_random(oneHotDf, seed=123)\n",
    "print(\"train length: \", len(train), \"| ratio: \", len(train)/len(oneHotDf))\n",
    "print(\"validate length: \", len(validate), \"| ratio: \", len(validate)/len(oneHotDf))\n",
    "print(\"test length: \", len(test), \"| ratio: \", len(test)/len(oneHotDf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move images to train, test, validate directories according to split:\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "def move_split_images(train, validate, test):\n",
    "    imagesPath = './images/'\n",
    "    trainPath = './images/train/'\n",
    "    validatePath = './images/validate/'\n",
    "    testPath = './images/test/'\n",
    "    newPaths = [trainPath, validatePath, testPath]\n",
    "    dfList = [train, validate, test]\n",
    "    for path in newPaths:\n",
    "        if os.path.isdir(path)==False:\n",
    "            os.mkdir(path)\n",
    "    \n",
    "    for df in dfList:\n",
    "        for idx, row in df.iterrows():\n",
    "            fileName = str(int(row['file_name']))+'.png'\n",
    "            filePath = os.path.join(imagesPath, fileName)\n",
    "            trainFilePath = os.path.join(trainPath, fileName)\n",
    "            validateFilePath = os.path.join(validatePath, fileName)\n",
    "            testFilePath = os.path.join(testPath, fileName)\n",
    "            if(df.equals(test)):\n",
    "                newFilePath = testFilePath\n",
    "            if(df.equals(train)):\n",
    "                newFilePath = trainFilePath\n",
    "            if(df.equals(validate)):\n",
    "                newFilePath = validateFilePath\n",
    "            if os.path.isfile(filePath):\n",
    "                shutil.move(filePath, newFilePath)\n",
    "            elif os.path.isfile(testFilePath):\n",
    "                shutil.move(testFilePath, newFilePath)\n",
    "            elif os.path.isfile(validateFilePath):\n",
    "                shutil.move(validateFilePath, newFilePath)\n",
    "            elif os.path.isfile(trainFilePath):\n",
    "                shutil.move(trainFilePath, newFilePath)\n",
    "            else:\n",
    "                print(\"File missing: \", fileName)\n",
    "\n",
    "move_split_images(train, validate, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hair_-1', 'hair_0', 'hair_1', 'hair_2', 'hair_3', 'hair_4', 'hair_5', 'eyeglasses_-1', 'eyeglasses_1', 'smiling_-1', 'smiling_1', 'young_-1', 'young_1', 'human_-1', 'human_1']\n"
     ]
    }
   ],
   "source": [
    "validatePath = './images/validate/'\n",
    "labels_cols = list(train)[1:]\n",
    "print(labels_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train length:  2739 | ratio:  0.6\n",
      "validate length:  913 | ratio:  0.2\n",
      "test length:  913 | ratio:  0.2\n"
     ]
    }
   ],
   "source": [
    "train, validate, test = split_dataset_random(filteredDf, seed=123)\n",
    "print(\"train length: \", len(train), \"| ratio: \", len(train)/len(oneHotDf))\n",
    "print(\"validate length: \", len(validate), \"| ratio: \", len(validate)/len(oneHotDf))\n",
    "print(\"test length: \", len(test), \"| ratio: \", len(test)/len(oneHotDf))\n",
    "\n",
    "move_split_images(train, validate, test)\n",
    "\n",
    "train_human = train[['file_name', 'human']]\n",
    "validate_human = validate[['file_name', 'human']]\n",
    "test_human = test[['file_name', 'human']]\n",
    "labels_cols = list(train_human)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://jovianlin.io/cat-crossentropy-vs-sparse-cat-crossentropy/\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150,150,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>hair_color</th>\n",
       "      <th>eyeglasses</th>\n",
       "      <th>smiling</th>\n",
       "      <th>young</th>\n",
       "      <th>human</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>1532</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>1587</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>608</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>2359</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>2458</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_name  hair_color  eyeglasses  smiling  young  human\n",
       "1388       1532           3          -1        1      1     -1\n",
       "1436       1587          -1          -1        1     -1      1\n",
       "550         608           1          -1        1      1      1\n",
       "2151       2359          -1           1       -1      1      1\n",
       "2242       2458           2           1        1      1     -1"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_human = train[['file_name', 'human_-1', 'human_1']]\n",
    "validate_human = validate[['file_name', 'human_-1', 'human_1']]\n",
    "test_human = test[['file_name', 'human_-1', 'human_1']]\n",
    "labels_cols = list(train_human)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['human']\n"
     ]
    }
   ],
   "source": [
    "print(labels_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2739 images belonging to 2 classes.\n",
      "Found 913 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0,\n",
    "        zoom_range=0,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#Takes the dataframe and the path to a directory and \n",
    "#generates batches of augmented/normalized data.\n",
    "\n",
    "trainPath = './images/train/'\n",
    "validatePath = './images/validate/'\n",
    "#labels_cols = list(train)[1:]\n",
    "labels_cols = list(train_human)[1:]\n",
    "\n",
    "train_gen = train_datagen.flow_from_dataframe(\n",
    "            dataframe = train_human,\n",
    "            directory = trainPath,\n",
    "            x_col = \"file_name\",\n",
    "            y_col = 'human',\n",
    "            has_ext = False,\n",
    "            target_size=(150,150),\n",
    "            color_mode='rgb',\n",
    "            class_mode='binary',\n",
    "            batch_size=batch_size)\n",
    "\n",
    "validation_gen = test_datagen.flow_from_dataframe(\n",
    "            dataframe = validate_human,\n",
    "            directory = validatePath,\n",
    "            x_col = \"file_name\",\n",
    "            y_col = 'human',\n",
    "            has_ext = False,\n",
    "            target_size=(150,150),\n",
    "            color_mode='rgb',\n",
    "            class_mode='binary',\n",
    "            batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "85/85 [==============================] - 51s 596ms/step - loss: 0.2952 - acc: 0.9062 - val_loss: 9.1649 - val_acc: 0.0100\n",
      "Epoch 2/50\n",
      "60/85 [====================>.........] - ETA: 13s - loss: 0.0275 - acc: 0.9922"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss')\n",
    "\n",
    "STEP_SIZE_TRAIN=train_gen.n//train_gen.batch_size\n",
    "STEP_SIZE_VALID=validation_gen.n//validation_gen.batch_size\n",
    "\n",
    "model.fit_generator(generator=train_gen,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=validation_gen,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=50,\n",
    "                    callbacks=[earlyStopping])\n",
    "\n",
    "#model.save_weights('.h5')\n",
    "model.save('human_detection.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 913 images.\n",
      "913/913 [==============================] - 7s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "testPath = './images/test/'\n",
    "\n",
    "test_gen = test_datagen.flow_from_dataframe(\n",
    "        dataframe = test_human,\n",
    "        directory = testPath,\n",
    "        x_col = \"file_name\",\n",
    "        y_col = labels_cols,\n",
    "        has_ext = False,\n",
    "        target_size=(150,150),\n",
    "        color_mode='rgb',\n",
    "        class_mode='other',\n",
    "        batch_size=1,\n",
    "        shuffle=False)\n",
    "\n",
    "test_gen.reset()\n",
    "\n",
    "probabilities = model.predict_generator(test_gen,verbose=1,steps=len(test_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 1 0\n",
      " 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 1 1 0 1 1 1 1\n",
      " 1 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 1 1 1 0 0 0 1 1\n",
      " 1 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 1 0 0 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0\n",
      " 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 0 1 0 1 0 0 0 1 1 1 0 0\n",
      " 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1 0 0 1 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 0 0 0 0 0 1 0 0 1 1 1 0 1\n",
      " 1 1 0 0 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 0 0 0 0 0 1 1 0 0 1 1 0 0 1 1 0 0 0\n",
      " 0 0 0 0 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 0\n",
      " 0 0 1 0 1 0 1 1 0 0 0 1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 0 1 0 1 0 1 1 1 0\n",
      " 1 0 1 0 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 1 0\n",
      " 0 1 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 1 0 1 0 0 0 0 1 0\n",
      " 0 0 1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 1 0 1 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 0 1\n",
      " 1 0 0 0 0 0 0 1 1 1 0 1 1 1 0 1 0 0 0 0 1 1 0 1 0 1 0 1 1 0 1 1 1 1 0 0 0\n",
      " 1 1 1 0 0 0 1 1 1 1 0 0 0 1 0 0 1 0 1 1 0 0 0 1 1 1 0 0 1 0 1 0 0 1 0 1 1\n",
      " 0 1 0 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 1 1 0 0 1 0 0 0 1 0 1 0\n",
      " 0 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 1 0 1 0 0 1 0 1 1 0 1 1 1 0 0 1 0 0\n",
      " 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 1 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 0 0\n",
      " 1 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 1 1 1 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1\n",
      " 1 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 1 1 1 0 1 0 0 0 1 1\n",
      " 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 1 0 1 1 0 0 0 0 1 1 1 1 0 1 0 1 1 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 0 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "class_labels_predicted = np.argmax(probabilities, axis=1)\n",
    "print(class_labels_predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    503\n",
      "1.0    410\n",
      "Name: human_1, dtype: int64 1.0    503\n",
      "0.0    410\n",
      "Name: human_-1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "n_human = test_human['human_1'].value_counts()\n",
    "n_not_human = test_human['human_-1'].value_counts()\n",
    "print(n_human, n_not_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.3307790e-23 1.0000000e+00]\n",
      " [1.4481164e-27 1.0000000e+00]\n",
      " [1.2297226e-27 1.0000000e+00]\n",
      " ...\n",
      " [1.0000000e+00 0.0000000e+00]\n",
      " [4.0981585e-30 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[281, 222],\n",
       "       [222, 188]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "inputdf = test_human.iloc[:,1:].values\n",
    "class_labels_input = np.argmax(inputdf, axis=1)\n",
    "class_labels_predicted = np.argmax(probabilities, axis=1)\n",
    "\n",
    "#y_true = np.array([0] * 503 + [1] * 410)\n",
    "#y_pred = probabilities > 0.5\n",
    "\n",
    "confusion_matrix(class_labels_input, class_labels_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 1 0\n",
      " 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 1 1 0 1 1 1 1\n",
      " 1 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 1 1 1 0 0 0 1 1\n",
      " 1 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 1 0 0 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0\n",
      " 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 0 1 0 1 0 0 0 1 1 1 0 0\n",
      " 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1 0 0 1 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 0 0 0 0 0 1 0 0 1 1 1 0 1\n",
      " 1 1 0 0 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 0 0 0 0 0 1 1 0 0 1 1 0 0 1 1 0 0 0\n",
      " 0 0 0 0 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 0\n",
      " 0 0 1 0 1 0 1 1 0 0 0 1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 1 1 0 1 0 1 0 1 1 1 0\n",
      " 1 0 1 0 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 1 0\n",
      " 0 1 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 1 0 1 0 0 0 0 1 0\n",
      " 0 0 1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 0 1 0 1 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 0 1\n",
      " 1 0 0 0 0 0 0 1 1 1 0 1 1 1 0 1 0 0 0 0 1 1 0 1 0 1 0 1 1 0 1 1 1 1 0 0 0\n",
      " 1 1 1 0 0 0 1 1 1 1 0 0 0 1 0 0 1 0 1 1 0 0 0 1 1 1 0 0 1 0 1 0 0 1 0 1 1\n",
      " 0 1 0 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1 0 1 0 0 1 1 0 0 1 0 0 0 1 0 1 0\n",
      " 0 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 1 0 1 0 0 1 0 1 1 0 1 1 1 0 0 1 0 0\n",
      " 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 1 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 0 0\n",
      " 1 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 1 1 1 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1\n",
      " 1 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 1 1 1 0 1 0 0 0 1 1\n",
      " 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 1 0 1 1 0 0 0 0 1 1 1 1 0 1 0 1 1 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 0 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(class_labels_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "913\n",
      "913\n"
     ]
    }
   ],
   "source": [
    "print(len(class_labels_input))\n",
    "print(len(class_labels_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>human_-1</th>\n",
       "      <th>human_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3812</th>\n",
       "      <td>4169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>2144</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4067</th>\n",
       "      <td>4457</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_name  human_-1  human_1\n",
       "9            14       0.0      1.0\n",
       "3812       4169       0.0      1.0\n",
       "1950       2144       1.0      0.0\n",
       "659         730       1.0      0.0\n",
       "4067       4457       1.0      0.0"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_human.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AMLSassignment",
   "language": "python",
   "name": "amlsassignment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
