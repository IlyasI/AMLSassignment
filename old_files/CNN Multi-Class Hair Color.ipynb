{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "%store -r \n",
    "\n",
    "#drop rows where hair_color = -1 to improve training accuracy\n",
    "train = train[train.hair_color != -1]\n",
    "validate = validate[validate.hair_color != -1]\n",
    "test = test[test.hair_color != -1]\n",
    "\n",
    "#restore train, validate, and test dataframes from other notebook\n",
    "def reset_images_to_main_dir(delete_dirs=True):\n",
    "    dest_dir = './images/'\n",
    "    walker = os.walk(dest_dir, followlinks=False)\n",
    "    rem_dirs = walker.__next__()[1]\n",
    " \n",
    "    for data in walker:\n",
    "        for files in data[2]:\n",
    "            try:\n",
    "                shutil.move(data[0] + os.sep + files, dest_dir)\n",
    "            except shutil.Error:\n",
    "                print(shutil.Error)\n",
    "                continue\n",
    "    if delete_dirs:\n",
    "        for dirs in rem_dirs:\n",
    "            shutil.rmtree(dest_dir + os.sep + dirs)\n",
    "\n",
    "def symlink_classes_images(train, validate, test, reset_images=False, \n",
    "                           delete_dirs=False):\n",
    "    if reset_images:\n",
    "        reset_images_to_main_dir(delete_dirs=delete_dirs)\n",
    "    imagesPath = os.path.abspath('./images/')\n",
    "    trainPath = os.path.abspath('./images/train/haircolor')\n",
    "    validatePath = os.path.abspath('./images/validate/haircolor')\n",
    "    testPath = os.path.abspath('./images/test/haircolor')\n",
    "    newPaths = [trainPath, validatePath, testPath]\n",
    "    dfList = [train, validate, test]\n",
    "    for path in newPaths:\n",
    "        if os.path.isdir(path)==False:\n",
    "            os.mkdir(path)\n",
    "    \n",
    "    for df in dfList:\n",
    "        for idx, row in df.iterrows():\n",
    "            hair_color = int(row['hair_color'])\n",
    "            pathAppend = str(hair_color)+'/'\n",
    "            \n",
    "            fileName = str(int(row['file_name']))+'.png'\n",
    "            filePath = os.path.join(imagesPath, fileName)\n",
    "            trainClassPath = os.path.join(trainPath, pathAppend)\n",
    "            trainFilePath = os.path.join(trainClassPath, fileName)\n",
    "            validateClassPath = os.path.join(validatePath, pathAppend)\n",
    "            validateFilePath = os.path.join(validateClassPath, fileName)\n",
    "            testClassPath = os.path.join(testPath, pathAppend)\n",
    "            testFilePath = os.path.join(testClassPath, fileName)\n",
    "            classPaths = [trainClassPath, validateClassPath, testClassPath]\n",
    "            for path in classPaths:\n",
    "                if os.path.isdir(path)==False:\n",
    "                    os.mkdir(path)\n",
    "            if(df.equals(test)):\n",
    "                newFilePath = testFilePath\n",
    "            if(df.equals(train)):\n",
    "                newFilePath = trainFilePath\n",
    "            if(df.equals(validate)):\n",
    "                newFilePath = validateFilePath\n",
    "            if os.path.isfile(filePath):\n",
    "                os.symlink(filePath, newFilePath)\n",
    "            elif os.path.isfile(testFilePath):\n",
    "                os.symlink(testFilePath, newFilePath)\n",
    "            elif os.path.isfile(validateFilePath):\n",
    "                os.symlink(validateFilePath, newFilePath)\n",
    "            elif os.path.isfile(trainFilePath):\n",
    "                os.symlink(trainFilePath, newFilePath)\n",
    "            else:\n",
    "                print(\"File missing: \", fileName)\n",
    "                \n",
    "symlink_classes_images(train, validate, test, reset_images=False, delete_dirs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hair = train[['file_name', 'hair_color']]\n",
    "train_hair = train_hair.reset_index(drop=True)\n",
    "validate_hair = validate[['file_name', 'hair_color']]\n",
    "validate_hair = validate_hair.reset_index(drop=True)\n",
    "test_hair = test[['file_name', 'hair_color']]\n",
    "test_hair = test_hair.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1    602\n",
      " 3    567\n",
      " 4    483\n",
      "-1    387\n",
      " 5    322\n",
      " 2    320\n",
      " 0     58\n",
      "Name: hair_color, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "n_hair = train_hair['hair_color'].value_counts()\n",
    "print(n_hair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(3, 128, 128)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "#model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2739 images belonging to 7 classes.\n",
      "Found 913 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "def get_ImageDataGenerator(shear_range=1, \n",
    "                           zoom_range=[-1,1], \n",
    "                           horizontal_flip=True,\n",
    "                           rotation_range=30,\n",
    "                           zca_whitening=True):\n",
    "    datagen = ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "                shear_range=shear_range,\n",
    "                zoom_range=zoom_range,\n",
    "                zca_whitening=zca_whitening,\n",
    "                horizontal_flip=horizontal_flip,\n",
    "                rotation_range = rotation_range,\n",
    "                data_format='channels_first')\n",
    "    \n",
    "    return datagen\n",
    "\n",
    "def get_flow_from_directory(ImageDataGenerator,\n",
    "                            img_dir,\n",
    "                            target_size=(128,128),\n",
    "                            class_mode='binary',\n",
    "                            batch_size=32,\n",
    "                            shuffle=True,\n",
    "                            seed=123):\n",
    "    gen = ImageDataGenerator.flow_from_directory(\n",
    "                            directory=img_dir,\n",
    "                            target_size=target_size,\n",
    "                            class_mode=class_mode,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=shuffle,\n",
    "                            seed=seed,\n",
    "                            follow_links=True)\n",
    "    return gen\n",
    "\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = get_ImageDataGenerator(shear_range=0,\n",
    "                                       zoom_range=0,\n",
    "                                       horizontal_flip=False)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = get_ImageDataGenerator()\n",
    "#Takes the dataframe and the path to a directory and \n",
    "#generates batches of augmented/normalized data.\n",
    "\n",
    "trainPath = './images/train/haircolor/'\n",
    "validatePath = './images/validate/haircolor/'\n",
    "batch_size = 32\n",
    "target_size=(128,128)\n",
    "class_mode='categorical'\n",
    "shuffle=True\n",
    "seed=123\n",
    "\n",
    "train_gen = get_flow_from_directory(train_datagen,\n",
    "                                    trainPath,\n",
    "                                    target_size,\n",
    "                                    class_mode,\n",
    "                                    batch_size,\n",
    "                                    shuffle,\n",
    "                                    seed)\n",
    "\n",
    "validation_gen = get_flow_from_directory(test_datagen,\n",
    "                                    validatePath,\n",
    "                                    target_size,\n",
    "                                    class_mode,\n",
    "                                    batch_size,\n",
    "                                    shuffle,\n",
    "                                    seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "#class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 #['cartoon', 'human'],\n",
    "                                                 #train_human.head(2720)['human'])\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0.001,\n",
    "                              patience=0,\n",
    "                              verbose=1, \n",
    "                              mode='auto',\n",
    "                              restore_best_weights=True)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', \n",
    "                       factor=0.2, \n",
    "                       patience=0, \n",
    "                       verbose=1, \n",
    "                       mode='auto', \n",
    "                       min_delta=0.01, \n",
    "                       cooldown=0, \n",
    "                       min_lr=0.001)\n",
    "train_gen.reset()\n",
    "validation_gen.reset()\n",
    "\n",
    "train_steps=train_gen.n/train_gen.batch_size\n",
    "valid_steps=validation_gen.n/validation_gen.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.59375 28.53125\n",
      "2739.0 913.0\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 32, 128, 128)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 126, 126)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 32, 63, 63)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32, 63, 63)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 32, 63, 63)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 64, 61, 61)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 64, 30, 30)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64, 30, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 64, 30, 30)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 64, 28, 28)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 64, 14, 14)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64, 14, 14)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               6423040   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7)                 3591      \n",
      "=================================================================\n",
      "Total params: 6,538,375\n",
      "Trainable params: 6,538,375\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(train_steps, valid_steps)\n",
    "print(train_steps*train_gen.batch_size, valid_steps*validation_gen.batch_size)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "86/85 [==============================] - 327s 4s/step - loss: 1.6689 - acc: 0.3028 - val_loss: 1.3368 - val_acc: 0.5038\n",
      "Epoch 2/50\n",
      "86/85 [==============================] - 315s 4s/step - loss: 1.1172 - acc: 0.5381 - val_loss: 0.9097 - val_acc: 0.6517\n",
      "Epoch 3/50\n",
      "86/85 [==============================] - 321s 4s/step - loss: 0.8117 - acc: 0.6826 - val_loss: 0.7984 - val_acc: 0.7218\n",
      "Epoch 4/50\n",
      "86/85 [==============================] - 505s 6s/step - loss: 0.6776 - acc: 0.7301 - val_loss: 0.5535 - val_acc: 0.7788\n",
      "Epoch 5/50\n",
      "86/85 [==============================] - 626s 7s/step - loss: 0.5682 - acc: 0.7738 - val_loss: 0.5475 - val_acc: 0.7766\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 6/50\n",
      "86/85 [==============================] - 441s 5s/step - loss: 0.4945 - acc: 0.7953 - val_loss: 0.5079 - val_acc: 0.7930\n",
      "Epoch 7/50\n",
      "86/85 [==============================] - 423s 5s/step - loss: 0.4362 - acc: 0.8264 - val_loss: 0.5200 - val_acc: 0.7963\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator=train_gen,\n",
    "                    steps_per_epoch=train_steps,\n",
    "                    validation_data=validation_gen,\n",
    "                    validation_steps=valid_steps,\n",
    "                    epochs=50,\n",
    "                    callbacks=[earlyStopping, LR],\n",
    "                    class_weight = 'auto')\n",
    "\n",
    "#model.save_weights('.h5')\n",
    "model.save_weights('hair_detection_from_dir.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 913 images belonging to 7 classes.\n",
      "913/913 [==============================] - 46s 50ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5078581957352798, 0.7929901423877328]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_gen = get_flow_from_directory(test_datagen,\n",
    "                                        validatePath,\n",
    "                                        target_size,\n",
    "                                        class_mode,\n",
    "                                        1,\n",
    "                                        False)\n",
    "\n",
    "validation_gen.reset()\n",
    "\n",
    "model.evaluate_generator(generator=validation_gen, steps=913, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 913 images belonging to 7 classes.\n",
      "913/913 [==============================] - 35s 38ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5042252017561488, 0.7995618838992333]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testPath = './images/test/haircolor'\n",
    "\n",
    "\n",
    "test_gen = get_flow_from_directory(test_datagen,\n",
    "                                    testPath,\n",
    "                                    target_size,\n",
    "                                    class_mode,\n",
    "                                    1,\n",
    "                                    False)\n",
    "\n",
    "test_gen.reset()\n",
    "\n",
    "model.evaluate_generator(generator=test_gen, steps=913, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "913/913 [==============================] - 35s 38ms/step\n"
     ]
    }
   ],
   "source": [
    "test_gen.reset()\n",
    "probabilities = model.predict_generator(test_gen,verbose=1,steps=len(test_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "output_df = pd.DataFrame(\n",
    "    {'filename': test_gen.filenames,\n",
    "     'y_true': test_gen.classes,\n",
    "     'y_pred': probabilities.argmax(axis=-1).flatten()\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 4, 0, 5, 4, 0, 0, 0, 0, 5, 2, 0, 0, 5, 5, 4, 0, 0, 0, 0, 5,\n",
       "       0, 0, 5, 4, 5, 0, 0, 5, 5, 4, 0, 0, 0, 0, 6, 5, 0, 0, 5, 0, 0, 5,\n",
       "       5, 5, 0, 4, 2, 0, 0, 0, 4, 4, 4, 0, 5, 2, 5, 4, 5, 0, 4, 4, 4, 0,\n",
       "       0, 5, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 0, 2, 4, 5, 0, 5, 0, 5, 6, 0,\n",
       "       6, 2, 0, 0, 5, 4, 0, 0, 0, 5, 0, 0, 4, 5, 0, 0, 0, 5, 2, 2, 0, 0,\n",
       "       0, 6, 0, 0, 0, 6, 0, 0, 4, 0, 0, 5, 5, 0, 2, 5, 0, 0, 4, 0, 4, 0,\n",
       "       0, 0, 0, 0, 0, 0, 4, 5, 0, 4, 0, 0, 5, 0, 0, 1, 6, 2, 2, 5, 0, 4,\n",
       "       4, 2, 0, 0, 4, 2, 2, 0, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 0, 2, 2, 2, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 6, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 5, 4, 4, 4,\n",
       "       4, 4, 2, 4, 0, 4, 4, 4, 2, 4, 0, 4, 0, 4, 4, 4, 0, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 0, 4, 4, 4, 4, 4, 0, 4,\n",
       "       4, 0, 4, 4, 4, 4, 4, 0, 4, 0, 4, 4, 4, 0, 4, 2, 4, 0, 4, 4, 4, 4,\n",
       "       4, 4, 2, 4, 4, 4, 4, 0, 0, 4, 4, 4, 4, 4, 4, 6, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 4, 0, 4, 4, 0, 4, 4, 4, 4, 0, 4,\n",
       "       4, 4, 5, 4, 4, 0, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4,\n",
       "       0, 4, 4, 5, 0, 0, 4, 4, 0, 4, 4, 0, 4, 0, 4, 4, 4, 5, 4, 4, 0, 4,\n",
       "       0, 4, 4, 4, 0, 4, 4, 4, 4, 4, 0, 2, 4, 4, 4, 4, 4, 4, 5, 0, 2, 5,\n",
       "       5, 5, 5, 0, 5, 5, 0, 0, 4, 0, 5, 5, 5, 5, 4, 5, 0, 5, 4, 5, 5, 5,\n",
       "       5, 5, 0, 4, 5, 4, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 0, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 0, 5, 0, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 0, 5, 5, 5, 5, 5, 4, 0, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 0,\n",
       "       5, 5, 0, 4, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 0, 4, 5, 5, 0, 5, 5,\n",
       "       5, 5, 4, 5, 5, 5, 5, 5, 5, 4, 5, 5, 4, 5, 5, 5, 5, 5, 5, 0, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 4, 6, 6, 6, 0, 6, 6, 6, 6, 6, 6, 0, 6, 6, 6, 6,\n",
       "       6, 6, 0, 6, 0, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 0, 6, 6, 6, 6, 6, 6, 6, 6, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 0, 2, 6, 6, 6, 6, 6, 6, 6, 6, 6, 2, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 2, 6, 6, 4, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 4, 6, 6, 6, 6, 6, 6, 6])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1/101.png</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1/102.png</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1/1044.png</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1/1058.png</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1/1088.png</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1/1185.png</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1/1295.png</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-1/1343.png</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-1/1372.png</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-1/1388.png</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-1/1514.png</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-1/157.png</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-1/1581.png</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-1/1602.png</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-1/1707.png</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-1/171.png</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-1/1753.png</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-1/1837.png</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>-1/1852.png</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-1/1908.png</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-1/218.png</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-1/22.png</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-1/2204.png</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-1/2222.png</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>-1/2228.png</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>-1/2324.png</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>-1/2332.png</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>-1/2351.png</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>-1/2360.png</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>-1/2402.png</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>4/3077.png</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>4/328.png</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>4/3450.png</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>4/3479.png</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>4/3767.png</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>4/3865.png</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>4/3927.png</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>4/3960.png</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>4/4169.png</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>4/4437.png</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>4/4492.png</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>4/4608.png</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>4/4683.png</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>4/4936.png</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>4/56.png</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>4/756.png</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>4/999.png</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>5/1179.png</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>5/147.png</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>5/1647.png</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>5/1832.png</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>5/1864.png</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>5/2433.png</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>5/293.png</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>5/3567.png</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>5/3657.png</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>5/4029.png</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>5/4807.png</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>5/4826.png</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>5/776.png</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        filename  y_true  y_pred\n",
       "0     -1/101.png       0       5\n",
       "1     -1/102.png       0       6\n",
       "2    -1/1044.png       0       4\n",
       "4    -1/1058.png       0       5\n",
       "5    -1/1088.png       0       4\n",
       "10   -1/1185.png       0       5\n",
       "11   -1/1295.png       0       2\n",
       "14   -1/1343.png       0       5\n",
       "15   -1/1372.png       0       5\n",
       "16   -1/1388.png       0       4\n",
       "21   -1/1514.png       0       5\n",
       "24    -1/157.png       0       5\n",
       "25   -1/1581.png       0       4\n",
       "26   -1/1602.png       0       5\n",
       "29   -1/1707.png       0       5\n",
       "30    -1/171.png       0       5\n",
       "31   -1/1753.png       0       4\n",
       "36   -1/1837.png       0       6\n",
       "37   -1/1852.png       0       5\n",
       "40   -1/1908.png       0       5\n",
       "43    -1/218.png       0       5\n",
       "44     -1/22.png       0       5\n",
       "45   -1/2204.png       0       5\n",
       "47   -1/2222.png       0       4\n",
       "48   -1/2228.png       0       2\n",
       "52   -1/2324.png       0       4\n",
       "53   -1/2332.png       0       4\n",
       "54   -1/2351.png       0       4\n",
       "56   -1/2360.png       0       5\n",
       "57   -1/2402.png       0       2\n",
       "..           ...     ...     ...\n",
       "718   4/3077.png       5       0\n",
       "727    4/328.png       5       0\n",
       "733   4/3450.png       5       4\n",
       "734   4/3479.png       5       0\n",
       "743   4/3767.png       5       4\n",
       "747   4/3865.png       5       0\n",
       "750   4/3927.png       5       0\n",
       "751   4/3960.png       5       4\n",
       "760   4/4169.png       5       0\n",
       "763   4/4437.png       5       0\n",
       "764   4/4492.png       5       4\n",
       "767   4/4608.png       5       0\n",
       "772   4/4683.png       5       4\n",
       "779   4/4936.png       5       4\n",
       "782     4/56.png       5       4\n",
       "789    4/756.png       5       0\n",
       "798    4/999.png       5       4\n",
       "802   5/1179.png       6       0\n",
       "809    5/147.png       6       0\n",
       "816   5/1647.png       6       0\n",
       "818   5/1832.png       6       0\n",
       "819   5/1864.png       6       0\n",
       "837   5/2433.png       6       0\n",
       "846    5/293.png       6       0\n",
       "862   5/3567.png       6       0\n",
       "863   5/3657.png       6       2\n",
       "873   5/4029.png       6       2\n",
       "892   5/4807.png       6       2\n",
       "895   5/4826.png       6       4\n",
       "905    5/776.png       6       4\n",
       "\n",
       "[183 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df_wrong = output_df.query('y_true != y_pred')\n",
    "output_df_wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 78,   0,   8,   0,  24,  31,   6],\n",
       "       [  3,   1,   4,   0,   3,   1,   1],\n",
       "       [  5,   1, 188,   1,   1,   0,   3],\n",
       "       [  0,   0,   1, 115,   1,   0,   0],\n",
       "       [ 29,   0,   7,   0, 138,   5,   1],\n",
       "       [ 20,   0,   1,   0,  13, 109,   0],\n",
       "       [  8,   0,   3,   0,   2,   0, 101]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_true = test_gen.classes\n",
    "y_pred = probabilities.argmax(axis=-1)\n",
    "confusion_matrix(y_true=y_true, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AMLSassignment",
   "language": "python",
   "name": "amlsassignment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
