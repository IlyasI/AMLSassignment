{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>hair_color</th>\n",
       "      <th>eyeglasses</th>\n",
       "      <th>smiling</th>\n",
       "      <th>young</th>\n",
       "      <th>human</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_name  hair_color  eyeglasses  smiling  young  human\n",
       "0          1           1          -1        1      1     -1\n",
       "1          2           4          -1        1      1      1\n",
       "2          3           5          -1        1     -1     -1\n",
       "3          7           2          -1        1      1     -1\n",
       "4          8           3          -1        1      1     -1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filteredDf = pd.read_csv('attribute_list_filtered.csv')\n",
    "filteredDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x0_-1' 'x0_0' 'x0_1' 'x0_2' 'x0_3' 'x0_4' 'x0_5' 'x1_-1' 'x1_1' 'x2_-1'\n",
      " 'x2_1' 'x3_-1' 'x3_1' 'x4_-1' 'x4_1']\n",
      "(4565, 15)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#one-hot-enconding:\n",
    "def get_one_hot():\n",
    "    df = pd.read_csv('attribute_list_filtered.csv')\n",
    "    fileNameDf = df['file_name']\n",
    "    df = df.drop('file_name', 1)\n",
    "    enc = OneHotEncoder(categories='auto')\n",
    "    enc.fit(df)\n",
    "    onehotlabels = enc.transform(df).toarray()\n",
    "    print(enc.get_feature_names())\n",
    "    print(onehotlabels.shape)\n",
    "    oneHotCols = [\"hair_-1\", \"hair_0\", \"hair_1\", \"hair_2\", \"hair_3\", \"hair_4\",\n",
    "              \"hair_5\", \"eyeglasses_-1\", \"eyeglasses_1\", \"smiling_-1\", \"smiling_1\", \n",
    "              \"young_-1\", \"young_1\", \"human_-1\", \"human_1\"]\n",
    "    oneHotDf = pd.DataFrame(onehotlabels, columns = oneHotCols)\n",
    "    oneHotDf = pd.concat([fileNameDf, oneHotDf], axis=1)\n",
    "    oneHotDf.to_csv('attribute_list_filtered_onehot.csv', index=False)\n",
    "    return oneHotDf\n",
    "\n",
    "oneHotDf = get_one_hot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4565"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(oneHotDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentation to prevent over-fitting example:\n",
    "'''https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html'''\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "def generate_transformed_images(image_path,\n",
    "                                output_path='transformed',\n",
    "                                rotiation_range=40, \n",
    "                                width_shift_range=0.2, \n",
    "                                height_shift_range=0.2, \n",
    "                                shear_range=0.2, \n",
    "                                zoom_range=0.2, \n",
    "                                horizontal_flip=True,\n",
    "                                fill_mode='nearest'):\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "            rotation_range=rotation_range,\n",
    "            width_shift_range=width_shift_range,\n",
    "            height_shift_range=height_shift_range,\n",
    "            shear_range=shear_range,\n",
    "            zoom_range=zoom_range,\n",
    "            horizontal_flip=horizontal_flip,\n",
    "            fill_mode=fill_mode)\n",
    "\n",
    "    img = load_img(image_path)\n",
    "    img_arr = img_to_array(img) #shape: (3, 256, 256)\n",
    "    img_arr = img_arr.reshape((1,)+img_arr.shape) #adds extra dimension, shape: (1,3,256,256)\n",
    "\n",
    "    #generate batches of randomly transformed images, save in transformed dir\n",
    "    if os.path.isdir(output_path)==False:\n",
    "        os.mkdir(output_path)\n",
    "\n",
    "    i = 0\n",
    "    flow = datagen.flow(img_arr, batch_size=1,\n",
    "                        save_to_dir=output_path, \n",
    "                        save_prefix=os.path.basename(image_path), \n",
    "                        save_format='png')\n",
    "    for batch in flow:\n",
    "        i+=1\n",
    "        if i>20:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into train, validation, and test sets:\n",
    "import numpy as np\n",
    "def split_dataset_random(df, validation_split=0.2, test_split=0.2, seed=0):\n",
    "    np.random.seed(seed) #if the same seed is used the same random split will be produced\n",
    "    train_split = 1 - validation_split - test_split\n",
    "    indeces_array = [int(train_split*len(df)), int((1-test_split)*len(df))]\n",
    "    '''example, [2, 3] would, for axis=0, result in\n",
    "\n",
    "        ary[:2]\n",
    "        ary[2:3]\n",
    "        ary[3:]\n",
    "\n",
    "    '''\n",
    "    train, validate, test = np.split(df.sample(frac=1), indeces_array)\n",
    "    return train, validate, test\n",
    "\n",
    "#train, validate, test = split_dataset_random(oneHotDf, seed=123)\n",
    "#print(\"train length: \", len(train), \"| ratio: \", len(train)/len(oneHotDf))\n",
    "#print(\"validate length: \", len(validate), \"| ratio: \", len(validate)/len(oneHotDf))\n",
    "#print(\"test length: \", len(test), \"| ratio: \", len(test)/len(oneHotDf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move images to train, test, validate directories according to split:\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "def move_split_images(train, validate, test):\n",
    "    imagesPath = './images/'\n",
    "    trainPath = './images/train/'\n",
    "    validatePath = './images/validate/'\n",
    "    testPath = './images/test/'\n",
    "    newPaths = [trainPath, validatePath, testPath]\n",
    "    dfList = [train, validate, test]\n",
    "    for path in newPaths:\n",
    "        if os.path.isdir(path)==False:\n",
    "            os.mkdir(path)\n",
    "    \n",
    "    for df in dfList:\n",
    "        for idx, row in df.iterrows():\n",
    "            fileName = str(int(row['file_name']))+'.png'\n",
    "            filePath = os.path.join(imagesPath, fileName)\n",
    "            trainFilePath = os.path.join(trainPath, fileName)\n",
    "            validateFilePath = os.path.join(validatePath, fileName)\n",
    "            testFilePath = os.path.join(testPath, fileName)\n",
    "            if(df.equals(test)):\n",
    "                newFilePath = testFilePath\n",
    "            if(df.equals(train)):\n",
    "                newFilePath = trainFilePath\n",
    "            if(df.equals(validate)):\n",
    "                newFilePath = validateFilePath\n",
    "            if os.path.isfile(filePath):\n",
    "                shutil.move(filePath, newFilePath)\n",
    "            elif os.path.isfile(testFilePath):\n",
    "                shutil.move(testFilePath, newFilePath)\n",
    "            elif os.path.isfile(validateFilePath):\n",
    "                shutil.move(validateFilePath, newFilePath)\n",
    "            elif os.path.isfile(trainFilePath):\n",
    "                shutil.move(trainFilePath, newFilePath)\n",
    "            else:\n",
    "                print(\"File missing: \", fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "def reset_images_to_main_dir():\n",
    "    dest_dir = './images/'\n",
    "    walker = os.walk(dest_dir)\n",
    "    rem_dirs = walker.__next__()[1]\n",
    " \n",
    "    for data in walker:\n",
    "        for files in data[2]:\n",
    "            try:\n",
    "                shutil.move(data[0] + os.sep + files, dest_dir)\n",
    "            except shutil.Error:\n",
    "                print(shutil.Error)\n",
    "                continue\n",
    "\n",
    "def move_classes_images(train, validate, test):\n",
    "    reset_images_to_main_dir()\n",
    "    imagesPath = './images/'\n",
    "    trainPath = './images/train/'\n",
    "    validatePath = './images/validate/'\n",
    "    testPath = './images/test/'\n",
    "    newPaths = [trainPath, validatePath, testPath]\n",
    "    dfList = [train, validate, test]\n",
    "    for path in newPaths:\n",
    "        if os.path.isdir(path)==False:\n",
    "            os.mkdir(path)\n",
    "    \n",
    "    for df in dfList:\n",
    "        for idx, row in df.iterrows():\n",
    "            if int(row['human'])==-1:\n",
    "                pathAppend = 'cartoon/'\n",
    "            elif int(row['human']==1):\n",
    "                pathAppend = 'human/'\n",
    "            fileName = str(int(row['file_name']))+'.png'\n",
    "            filePath = os.path.join(imagesPath, fileName)\n",
    "            trainClassPath = os.path.join(trainPath, pathAppend)\n",
    "            trainFilePath = os.path.join(trainClassPath, fileName)\n",
    "            validateClassPath = os.path.join(validatePath, pathAppend)\n",
    "            validateFilePath = os.path.join(validateClassPath, fileName)\n",
    "            testClassPath = os.path.join(testPath, pathAppend)\n",
    "            testFilePath = os.path.join(testClassPath, fileName)\n",
    "            classPaths = [trainClassPath, validateClassPath, testClassPath]\n",
    "            for path in classPaths:\n",
    "                if os.path.isdir(path)==False:\n",
    "                    os.mkdir(path)\n",
    "            if(df.equals(test)):\n",
    "                newFilePath = testFilePath\n",
    "            if(df.equals(train)):\n",
    "                newFilePath = trainFilePath\n",
    "            if(df.equals(validate)):\n",
    "                newFilePath = validateFilePath\n",
    "            if os.path.isfile(filePath):\n",
    "                shutil.move(filePath, newFilePath)\n",
    "            elif os.path.isfile(testFilePath):\n",
    "                shutil.move(testFilePath, newFilePath)\n",
    "            elif os.path.isfile(validateFilePath):\n",
    "                shutil.move(validateFilePath, newFilePath)\n",
    "            elif os.path.isfile(trainFilePath):\n",
    "                shutil.move(trainFilePath, newFilePath)\n",
    "            else:\n",
    "                print(\"File missing: \", fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validatePath = './images/validate/'\n",
    "#labels_cols = list(train)[1:]\n",
    "#print(labels_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train length:  2739 | ratio:  0.6\n",
      "validate length:  913 | ratio:  0.2\n",
      "test length:  913 | ratio:  0.2\n",
      "Stored 'train' (DataFrame)\n",
      "Stored 'validate' (DataFrame)\n",
      "Stored 'test' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "def get_data_split(df=oneHotDf, seed=123):\n",
    "    train, validate, test = split_dataset_random(df, seed=111)\n",
    "    print(\"train length: \", len(train), \"| ratio: \", len(train)/len(filteredDf))\n",
    "    print(\"validate length: \", len(validate), \"| ratio: \", len(validate)/len(filteredDf))\n",
    "    print(\"test length: \", len(test), \"| ratio: \", len(test)/len(filteredDf))\n",
    "\n",
    "    move_split_images(train, validate, test)\n",
    "    \n",
    "    return train, validate, test\n",
    "\n",
    "train, validate, test = get_data_split(df=filteredDf, seed=0)\n",
    "%store train\n",
    "%store validate\n",
    "%store test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_classes_images(train, validate, test):\n",
    "    reset_images_to_main_dir()\n",
    "    imagesPath = './images/'\n",
    "    trainPath = './images/train/'\n",
    "    validatePath = './images/validate/'\n",
    "    testPath = './images/test/'\n",
    "    newPaths = [trainPath, validatePath, testPath]\n",
    "    dfList = [train, validate, test]\n",
    "    for path in newPaths:\n",
    "        if os.path.isdir(path)==False:\n",
    "            os.mkdir(path)\n",
    "    \n",
    "    for df in dfList:\n",
    "        for idx, row in df.iterrows():\n",
    "            if int(row['human'])==-1:\n",
    "                pathAppend = 'cartoon/'\n",
    "            elif int(row['human']==1):\n",
    "                pathAppend = 'human/'\n",
    "            fileName = str(int(row['file_name']))+'.png'\n",
    "            filePath = os.path.join(imagesPath, fileName)\n",
    "            trainClassPath = os.path.join(trainPath, pathAppend)\n",
    "            trainFilePath = os.path.join(trainClassPath, fileName)\n",
    "            validateClassPath = os.path.join(validatePath, pathAppend)\n",
    "            validateFilePath = os.path.join(validateClassPath, fileName)\n",
    "            testClassPath = os.path.join(testPath, pathAppend)\n",
    "            testFilePath = os.path.join(testClassPath, fileName)\n",
    "            classPaths = [trainClassPath, validateClassPath, testClassPath]\n",
    "            for path in classPaths:\n",
    "                if os.path.isdir(path)==False:\n",
    "                    os.mkdir(path)\n",
    "            if(df.equals(test)):\n",
    "                newFilePath = testFilePath\n",
    "            if(df.equals(train)):\n",
    "                newFilePath = trainFilePath\n",
    "            if(df.equals(validate)):\n",
    "                newFilePath = validateFilePath\n",
    "            if os.path.isfile(filePath):\n",
    "                shutil.move(filePath, newFilePath)\n",
    "            elif os.path.isfile(testFilePath):\n",
    "                shutil.move(testFilePath, newFilePath)\n",
    "            elif os.path.isfile(validateFilePath):\n",
    "                shutil.move(validateFilePath, newFilePath)\n",
    "            elif os.path.isfile(trainFilePath):\n",
    "                shutil.move(trainFilePath, newFilePath)\n",
    "            else:\n",
    "                print(\"File missing: \", fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_images_to_main_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AMLSassignment",
   "language": "python",
   "name": "amlsassignment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
